
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Logistic regression &#8212; Introduction to Data Science for Mechanical Engineers (Lecture Book)</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Example: Logistic regression with one variable (High melting explosives)" href="example-logistic-regression-one-variable.html" />
    <link rel="prev" title="Lecture 16: Classification via logistic regression" href="intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Data Science for Mechanical Engineers (Lecture Book)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Preface
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture01/intro.html">
   Lecture 1: Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture01/what-is-data-science.html">
     What is data science?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture01/cool-applications.html">
     Some cool appliations of data science in mechanical engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture01/python-intro.html">
     Why Python?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture01/python-expressions.html">
     Python expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture01/python-variables-and-types.html">
     Python variables and types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture01/homework_01.html">
     Homework 1
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture02/intro.html">
   Lecture 2: Data arrays
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture02/python-tuples.html">
     Python tuples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture02/python-lists.html">
     Python lists
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture02/python-numpy.html">
     Numerical Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture02/homework_02.html">
     Homework 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture03/intro.html">
   Lecture 3: Data loading and selection
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture03/python-matrices.html">
     Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture03/python-csv-files.html">
     Comma-separated values file format
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture03/python-pandas.html">
     The Python data analysis library
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture03/homework_03.html">
     Homework 3
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture04/intro.html">
   Lecture 4: Data visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture04/python-plotting.html">
     Plotting simple functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture04/python-plot-noisy.html">
     Plotting noisy measurements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture04/python-scatter.html">
     Scatter plots
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture04/python-histograms.html">
     Histograms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture04/homework_04.html">
     Homework 4
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture05/intro.html">
   Lecture 5: Functions, data manipulation, and models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture05/python-strings.html">
     Basics of strings
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture05/python-print.html">
     The print function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture05/python-functions.html">
     Python functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture05/applying-functions-to-dataframes.html">
     Applying functions to dataframes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture05/models-are-functions.html">
     Models are functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture05/homework_05.html">
     Homework 5
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture06/intro.html">
   Lecture 6: Conditionals and loops
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture06/python-conditionals.html">
     Python conditionals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture06/python-loops.html">
     Python loops
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture06/python-pandas-selections.html">
     Selecting dataframe rows that satisfy a boolean expression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture06/homework_06.html">
     Homework 6
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture07/intro.html">
   Lecture 7: Probability as a measure of uncertainty
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture07/probability-and-state-of-knowledge.html">
     Probability as a representation of our state of knowledge
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture07/probability-common-sense.html">
     The common sense assumptions that give rise to the basic probability rules.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture07/principle-of-insufficient-reason.html">
     The principle of insufficient reason
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture07/estimating-probabilities-by-simulation.html">
     Estimating probabilities by simulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture07/estimating-probabilities-from-data.html">
     Estimating probabilities from data - Bootstrapping
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture07/homework_07.html">
     Homework 7
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture08/intro.html">
   Lecture 8: The basic rules of probability
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture08/probability-rules.html">
     The basic rules of probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture08/probability-urn-example.html">
     Example - Drawing balls from a box without replacement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture08/probability-of-disjunction.html">
     Probability of logical disjunctions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture08/probability-sum-rule.html">
     The sum rule
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture08/probability-urn-example-sum-rule.html">
     Example - Drawing balls from a box without replacement (sum rule)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture08/probability-urn-example-information-flow.html">
     Example - Drawing balls from a box without replacement (information flow)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture08/homework_08.html">
     Homework 8
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture09/intro.html">
   Lecture 9: Discrete random variables
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture09/discrete-random-variables.html">
     Discrete Random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture09/probability-mass-function.html">
     The probability mass function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture09/the-bernoulli-distribution.html">
     The Bernoulli distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture09/properties-of-the-probability-mass-function.html">
     Properties of the probability mass function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture09/the-categorical-distribution.html">
     The Categorical distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture09/the-binomial-distribution.html">
     The Binomial Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture09/the-poisson-distribution.html">
     The Poisson distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture09/homework_09.html">
     Homework 9
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture10/intro.html">
   Lecture 10: Continuous random variables
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture10/continuous-random-variables.html">
     Continuous random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture10/example-manufacturing-steel-balls.html">
     Example: Uncertainties in steel ball manufacturing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture10/cumulative-distribution-function.html">
     The cumulative distribution function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture10/probability-density-function.html">
     The probability density function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture10/the-uniform-distribution.html">
     The uniform distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture10/homework_10.html">
     Homework 10
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture11/intro.html">
   Lecture 11: Expectations, variances, and their properties
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/expectation-discrete-rv.html">
     Expectation of discrete random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/examples-expectation-of-discrete-rvs.html">
     Examples of expectations of discrete random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/expectation-continuous-rv.html">
     Expectation of a continuous random variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/expectation-notation.html">
     Simplifying our notation about expectations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/properties-of-expectations.html">
     Properties of expectations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/variance.html">
     Variance of a random variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/properties-of-variance.html">
     Properties of variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/examples-variance.html">
     Examples of variances of random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/homework_11.html">
     Homework 11
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture12/intro.html">
   Lecture 12: The Normal distribution, quantiles, and credible intervals
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture12/the-standard-normal.html">
     The standard Normal distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture12/standard-normal-quantiles.html">
     Quantiles of the standard Normal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture12/the-normal.html">
     The Normal distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture12/normal-quantiles.html">
     Quantiles of the Normal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture12/example-fitting-normals.html">
     Fitting Normal distributions to data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture12/homework_12.html">
     Homework 12
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture13/intro.html">
   Lecture 13: Fitting models with the principle of maximum likelihood
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture13/joint-probability-density-function.html">
     The joint probability density function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture13/repeated-experiments.html">
     Repeated independent experiments
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture13/the-maximum-likelihood-principle.html">
     The maximum likelihood principle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture13/fitting-the-normal-with-maximum-likelihood.html">
     Fitting the parameters of a Normal using the maximum likelihood principle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture13/fitting-the-bernoulli.html">
     Fitting the Bernoulli with maximum likelihood
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture13/predictive-checking.html">
     Predictive checking
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture13/homework_13.html">
     Homework 13
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture14/intro.html">
   Lecture 14: Covariance, correlation, and linear regression with one variable
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture14/covariance.html">
     Covariance between two random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture14/correlation.html">
     Correlation between two random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture14/correlation-is-not-causation.html">
     Correlation is not causation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture14/uncorrelated-does-not-imply-independent.html">
     Two uncorrelated random variables are not necessarily independent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture14/linear-regression-with-one-variable.html">
     Linear regression with one variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture14/homework_14.html">
     Homework 14
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture15/intro.html">
   Lecture 15: Linear regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture15/regression-with-one-variable-revisited.html">
     Regression with one variable revisited
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture15/example-linear-regression.html">
     Example: Linear regression with a single variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture15/polynomial-regression.html">
     Polynomial Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture15/the-generalized-linear-model.html">
     The generalized linear model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture15/regression-diagnostics.html">
     Measures of Predictive Accuracy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture15/cross-validation.html">
     Cross validation for selecting the number of basis functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture15/maximum-likelihood-interpretation.html">
     Maximum likelihood interpretation of least squares
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture15/maximum-likelihood-example.html">
     Example: Regression with estimated measurement noise
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture15/homework_15.html">
     Homework 15
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="intro.html">
   Lecture 16: Classification via logistic regression
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="example-logistic-regression-one-variable.html">
     Example: Logistic regression with one variable (High melting explosives)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="example-logistic-regression-many-features.html">
     Logistic regression with many features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification-diagnostics.html">
     Diagnostics for Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="homework_16.html">
     Homework 16
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bibliography.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/lecture16/logistic-regression.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="logistic-regression">
<span id="lecture16-logistic-regression"></span><h1>Logistic regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">¶</a></h1>
<p>Imagine that you have a bunch of observations consisting of inputs/features <span class="math notranslate nohighlight">\(\mathbf{x}_{1:N}=(\mathbf{x}_1,\dots,\mathbf{x}_N)\)</span> and the corresponding targets <span class="math notranslate nohighlight">\(y_{1:N}=(y_1,\dots,y_N)\)</span>.
Remember that we say that we have a classification problem when the targets are discrete labels.
In particular, if the labels are two, say 0 or 1, then we say that we have a <em>binary classification problem</em>.</p>
<p>The logistic regression model is one of the simplest ways to solve the binary classification problem.
It goes as follows.
You model the probability that <span class="math notranslate nohighlight">\(y=1\)</span> conditioned on having <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> by:</p>
<div class="math notranslate nohighlight">
\[
p(y=1|\mathbf{x},\mathbf{w}) = \operatorname{sigm}\left(\sum_{j=1}^Mw_j\phi_j(\mathbf{x})\right) =  \operatorname{sigm}\left(\mathbf{w}^T\boldsymbol{\phi}(\mathbf{x})\right),
\]</div>
<p>where <span class="math notranslate nohighlight">\(\operatorname{sigm}\)</span> is the <a class="reference external" href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid function</a>, the <span class="math notranslate nohighlight">\(\phi_j(\mathbf{x})\)</span> are <span class="math notranslate nohighlight">\(m\)</span> basis functions/features,</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\phi}(\mathbf{x}) = \left(\phi_1(\mathbf{x}),\dots,\phi_M(\mathbf{x})\right)
\]</div>
<p>and the <span class="math notranslate nohighlight">\(w_j\)</span>’s are <span class="math notranslate nohighlight">\(m\)</span> weights that we need to learn from the data.
The sigmoid function is defined by:</p>
<div class="math notranslate nohighlight">
\[
\operatorname{sigm}(z) = \frac{1}{1+e^{-z}},
\]</div>
<p>and all it does is it takes a real number and maps it to <span class="math notranslate nohighlight">\([0,1]\)</span> so that it can represent a probability, see <a class="reference internal" href="#sigmoid"><span class="std std-numref">Fig. 12</span></a>.
In other words, logistic regression is just a generalized linear model passed through the sigmoid function so that it is mapped to <span class="math notranslate nohighlight">\([0,1]\)</span>.</p>
<div class="figure align-default" id="sigmoid">
<a class="reference internal image-reference" href="../_images/sigmoid.png"><img alt="../_images/sigmoid.png" src="../_images/sigmoid.png" style="height: 250px;" /></a>
<p class="caption"><span class="caption-number">Fig. 12 </span><span class="caption-text">The sigmoid function takes any number and maps it to the unit interval <span class="math notranslate nohighlight">\([0, 1]\)</span>.
We use it at the end of models that are supposed to spit out probabilities.</span><a class="headerlink" href="#sigmoid" title="Permalink to this image">¶</a></p>
</div>
<p>If you need the probability of <span class="math notranslate nohighlight">\(y=0\)</span>, it is given by the obvious rule:</p>
<div class="math notranslate nohighlight">
\[
p(y=0|\mathbf{x},\mathbf{w}) = 1 - p(y=1|\mathbf{x},\mathbf{w}) = 1 - \operatorname{sigm}\left(\mathbf{w}^T\boldsymbol{\phi}(\mathbf{x})\right)
\]</div>
<p>You can represent the probability of an arbitrary label <span class="math notranslate nohighlight">\(y\)</span> conditioned on <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> using this simple trick:</p>
<div class="math notranslate nohighlight">
\[
p(y|\mathbf{x},\mathbf{w}) =
\left[\operatorname{sigm}\left(\mathbf{w}^T\boldsymbol{\phi}(\mathbf{x})\right)\right]^y
\left[1-\operatorname{sigm}\left(\mathbf{w}^T\boldsymbol{\phi}(\mathbf{x})\right)\right]^{1-y}.
\]</div>
<p>Notice that when <span class="math notranslate nohighlight">\(y=1\)</span>, the exponent of the second term becomes zero and thus the term becomes one.
Similarly, when <span class="math notranslate nohighlight">\(y=0\)</span>, the exponent of the first tierm becomes zero and thus the term becomes one.
This gives the right probability for each case.</p>
<p>The likelihood of all the observed data is:</p>
<div class="math notranslate nohighlight">
\[
p(y_{1:N}|\mathbf{x}_{1:n},\mathbf{w}) = \prod_{i=1}^Np(y_i |\mathbf{x}_i, \mathbf{w})
= \prod_{i=1}^N
\left[\operatorname{sigm}\left(\mathbf{w}^T\boldsymbol{\phi}(\mathbf{x}_i)\right)\right]^{y_i}
\left[1-\operatorname{sigm}\left(\mathbf{w}^T\boldsymbol{\phi}(\mathbf{x}_i)\right)\right]^{1-y_i}.
\]</div>
<p>We can now find the best weight vector <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> using the <a class="reference internal" href="../lecture13/the-maximum-likelihood-principle.html#lecture13-the-maximum-likelihood-principle"><span class="std std-ref">maximum likelihood principle</span></a>.
We need to solve the optimization problem:</p>
<div class="math notranslate nohighlight">
\[
\max_{\mathbf{w}}\log p(y_{1:N}|\mathbf{x}_{1:n},\mathbf{w})
= \max_{\mathbf{w}}\sum_{i=1}^N\left\{y_i\operatorname{sigm}\left(\mathbf{w}^T\boldsymbol{\phi}(\mathbf{x}_i)\right)+(1-y_i)\left[1-\operatorname{sigm}\left(\mathbf{w}^T\boldsymbol{\phi}(\mathbf{x}_i)\right)\right]\right\}.
\]</div>
<p>Notice that the following maximization problem is equivalent to minimizing this loss function:</p>
<div class="math notranslate nohighlight">
\[
L(\mathbf{w}) = -\sum_{i=1}^N\left\{y_i\operatorname{sigm}\left(\mathbf{w}^T\boldsymbol{\phi}(\mathbf{x}_i)\right)+(1-y_i)\left[1-\operatorname{sigm}\left(\mathbf{w}^T\boldsymbol{\phi}(\mathbf{x}_i)\right)\right]\right\}.
\]</div>
<p>This is known as the <a class="reference external" href="https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression">cross-entropy loss function</a> and you are very likely to encounter it if you dive deeper into modern data science.
For example, we use the same loss function to train state-of-the-art deep neural networks that classify images.
You now know that it does not come out of the blue.
It comes from the maximum likelihood principle.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is not possible to analytically minimize the cross-entropy loss function.
The optimization is usually done with a numerical optimization technique.
For small datasets, we can use a gradient-based optimization (e.g., <a class="reference external" href="https://en.wikipedia.org/wiki/Conjugate_gradient_method">the conjugate gradient method</a>, or the <a class="reference external" href="https://en.wikipedia.org/wiki/Newton%27s_method">Newton-Raphson method</a>).
The details of this optimization algorithm are beyond the scope of the present course.
You can learn about them in a course like <a class="reference external" href="https://nanohub.org/resources/purdueme581">ME 581</a>.
For large datasets, this is typically the case for deep learning, we use variants of <a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">stochastic gradient descent</a>.
To learn more about this take a course like <a class="reference external" href="https://github.com/PredictiveScienceLab/data-analytics-se">ME 539</a>.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./lecture16"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">Lecture 16: Classification via logistic regression</a>
    <a class='right-next' id="next-link" href="example-logistic-regression-one-variable.html" title="next page">Example: Logistic regression with one variable (High melting explosives)</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Ilias Bilionis (ibilion[at]purdue.edu)<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>