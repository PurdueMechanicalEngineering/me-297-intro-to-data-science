
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Regression with one variable revisited &#8212; Introduction to Data Science for Mechanical Engineers (Lecture Book)</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Example: Linear regression with a single variable" href="example-linear-regression.html" />
    <link rel="prev" title="Lecture 15: Linear regression" href="intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Introduction to Data Science for Mechanical Engineers (Lecture Book)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Preface
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture01/intro.html">
   Lecture 1: Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture01/what-is-data-science.html">
     What is data science?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture01/cool-applications.html">
     Some cool appliations of data science in mechanical engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture01/python-intro.html">
     Why Python?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture01/python-expressions.html">
     Python expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture01/python-variables-and-types.html">
     Python variables and types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture01/homework_01.html">
     Homework 1
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture02/intro.html">
   Lecture 2: Data arrays
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture02/python-tuples.html">
     Python tuples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture02/python-lists.html">
     Python lists
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture02/python-numpy.html">
     Numerical Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture02/homework_02.html">
     Homework 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture03/intro.html">
   Lecture 3: Data loading and selection
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture03/python-matrices.html">
     Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture03/python-csv-files.html">
     Comma-separated values file format
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture03/python-pandas.html">
     The Python data analysis library
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture03/homework_03.html">
     Homework 3
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture04/intro.html">
   Lecture 4: Data visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture04/python-plotting.html">
     Plotting simple functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture04/python-plot-noisy.html">
     Plotting noisy measurements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture04/python-scatter.html">
     Scatter plots
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture04/python-histograms.html">
     Histograms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture04/homework_04.html">
     Homework 4
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture05/intro.html">
   Lecture 5: Functions, data manipulation, and models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture05/python-strings.html">
     Basics of strings
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture05/python-print.html">
     The print function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture05/python-functions.html">
     Python functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture05/applying-functions-to-dataframes.html">
     Applying functions to dataframes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture05/models-are-functions.html">
     Models are functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture05/homework_05.html">
     Homework 5
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture06/intro.html">
   Lecture 6: Conditionals and loops
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture06/python-conditionals.html">
     Python conditionals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture06/python-loops.html">
     Python loops
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture06/python-pandas-selections.html">
     Selecting dataframe rows that satisfy a boolean expression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture06/homework_06.html">
     Homework 6
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture07/intro.html">
   Lecture 7: Probability as a measure of uncertainty
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture07/probability-and-state-of-knowledge.html">
     Probability as a representation of our state of knowledge
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture07/probability-common-sense.html">
     The common sense assumptions that give rise to the basic probability rules.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture07/principle-of-insufficient-reason.html">
     The principle of insufficient reason
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture07/estimating-probabilities-by-simulation.html">
     Estimating probabilities by simulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture07/estimating-probabilities-from-data.html">
     Estimating probabilities from data - Bootstrapping
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture07/homework_07.html">
     Homework 7
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture08/intro.html">
   Lecture 8: The basic rules of probability
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture08/probability-rules.html">
     The basic rules of probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture08/probability-urn-example.html">
     Example - Drawing balls from a box without replacement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture08/probability-of-disjunction.html">
     Probability of logical disjunctions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture08/probability-sum-rule.html">
     The sum rule
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture08/probability-urn-example-sum-rule.html">
     Example - Drawing balls from a box without replacement (sum rule)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture08/probability-urn-example-information-flow.html">
     Example - Drawing balls from a box without replacement (information flow)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture08/homework_08.html">
     Homework 8
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture09/intro.html">
   Lecture 9: Discrete random variables
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture09/discrete-random-variables.html">
     Discrete Random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture09/probability-mass-function.html">
     The probability mass function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture09/the-bernoulli-distribution.html">
     The Bernoulli distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture09/properties-of-the-probability-mass-function.html">
     Properties of the probability mass function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture09/the-categorical-distribution.html">
     The Categorical distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture09/the-binomial-distribution.html">
     The Binomial Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture09/the-poisson-distribution.html">
     The Poisson distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture09/homework_09.html">
     Homework 9
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture10/intro.html">
   Lecture 10: Continuous random variables
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture10/continuous-random-variables.html">
     Continuous random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture10/example-manufacturing-steel-balls.html">
     Example: Uncertainties in steel ball manufacturing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture10/cumulative-distribution-function.html">
     The cumulative distribution function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture10/probability-density-function.html">
     The probability density function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture10/the-uniform-distribution.html">
     The uniform distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture10/homework_10.html">
     Homework 10
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture11/intro.html">
   Lecture 11: Expectations, variances, and their properties
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/expectation-discrete-rv.html">
     Expectation of discrete random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/examples-expectation-of-discrete-rvs.html">
     Examples of expectations of discrete random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/expectation-continuous-rv.html">
     Expectation of a continuous random variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/expectation-notation.html">
     Simplifying our notation about expectations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/properties-of-expectations.html">
     Properties of expectations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/variance.html">
     Variance of a random variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/properties-of-variance.html">
     Properties of variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/examples-variance.html">
     Examples of variances of random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture11/homework_11.html">
     Homework 11
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture12/intro.html">
   Lecture 12: The Normal distribution, quantiles, and credible intervals
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture12/the-standard-normal.html">
     The standard Normal distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture12/standard-normal-quantiles.html">
     Quantiles of the standard Normal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture12/the-normal.html">
     The Normal distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture12/normal-quantiles.html">
     Quantiles of the Normal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture12/example-fitting-normals.html">
     Fitting Normal distributions to data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture12/homework_12.html">
     Homework 12
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture13/intro.html">
   Lecture 13: Fitting models with the principle of maximum likelihood
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture13/joint-probability-density-function.html">
     The joint probability density function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture13/repeated-experiments.html">
     Repeated independent experiments
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture13/the-maximum-likelihood-principle.html">
     The maximum likelihood principle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture13/fitting-the-normal-with-maximum-likelihood.html">
     Fitting the parameters of a Normal using the maximum likelihood principle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture13/fitting-the-bernoulli.html">
     Fitting the Bernoulli with maximum likelihood
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture13/predictive-checking.html">
     Predictive checking
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture13/homework_13.html">
     Homework 13
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture14/intro.html">
   Lecture 14: Covariance, correlation, and linear regression with one variable
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture14/covariance.html">
     Covariance between two random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture14/correlation.html">
     Correlation between two random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture14/correlation-is-not-causation.html">
     Correlation is not causation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture14/uncorrelated-does-not-imply-independent.html">
     Two uncorrelated random variables are not necessarily independent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture14/linear-regression-with-one-variable.html">
     Linear regression with one variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture14/homework_14.html">
     Homework 14
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="intro.html">
   Lecture 15: Linear regression
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Regression with one variable revisited
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="example-linear-regression.html">
     Example: Linear regression with a single variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="polynomial-regression.html">
     Polynomial Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="the-generalized-linear-model.html">
     The generalized linear model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="regression-diagnostics.html">
     Measures of Predictive Accuracy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cross-validation.html">
     Cross validation for selecting the number of basis functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="maximum-likelihood-interpretation.html">
     Maximum likelihood interpretation of least squares
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="maximum-likelihood-example.html">
     Example: Regression with estimated measurement noise
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="homework_15.html">
     Homework 15
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../lecture16/intro.html">
   Lecture 16: Classification via logistic regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture16/logistic-regression.html">
     Logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture16/example-logistic-regression-one-variable.html">
     Example: Logistic regression with one variable (High melting explosives)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture16/example-logistic-regression-many-features.html">
     Logistic regression with many features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture16/classification-diagnostics.html">
     Diagnostics for Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../lecture16/homework_16.html">
     Homework 16
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bibliography.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/lecture15/regression-with-one-variable-revisited.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Regression with one variable revisited</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="regression-with-one-variable-revisited">
<span id="lecture15-regression-with-one-variable-revisited"></span><h1>Regression with one variable revisited<a class="headerlink" href="#regression-with-one-variable-revisited" title="Permalink to this headline">¶</a></h1>
<p>Let’s say that we have a <span class="math notranslate nohighlight">\(N\)</span> observations consisting of inputs (features):</p>
<div class="math notranslate nohighlight">
\[
x_{1:N} = (x_1,\dots,x_N),
\]</div>
<p>and outputs (targets):</p>
<div class="math notranslate nohighlight">
\[
y_{1:N} = (y_1,\dots,y_N).
\]</div>
<p>We want to learn the map (function) that connects the inputs to the outputs.
We say that we have a <em>regression</em> problem when the outputs are continuous quantities, e.g., mass, height, price.
When the outputs are discrete, e.g., colors, numbers, then we say that we have a <em>classification</em> problem.
In this lecture, the focus will be on regression.</p>
<p>To proceed, you need to make a model that connects the inputs to the outputs.
The simplest such model is:</p>
<div class="math notranslate nohighlight">
\[
y = w_0 + w_1 x + \text{measurement noise}.
\]</div>
<p>This is the linear model we saw in the previous lecture with <span class="math notranslate nohighlight">\(w_0 = b\)</span> and <span class="math notranslate nohighlight">\(w_1 = a\)</span>.
The parameters <span class="math notranslate nohighlight">\(w_0\)</span> and <span class="math notranslate nohighlight">\(w_1\)</span> are called the regression <em>weights</em> and we need to find them using the observations <span class="math notranslate nohighlight">\(x_{1:N}\)</span> and <span class="math notranslate nohighlight">\(y_{1:N}\)</span>.</p>
<p>In the previous lecture, we fitted the model by minimizing the sum of square errors:</p>
<div class="math notranslate nohighlight">
\[
L(w_0, w_1) = \sum_{i=1}^N(y_i - w_0 - w_1 x_i)^2.
\]</div>
<p>Now we are going to express this equation using linear algebra.
We do this for two reasons:</p>
<ul class="simple">
<li><p>It is a lot of fun!</p></li>
<li><p>It is essential for formulating the fitting problem for more complicated models.</p></li>
</ul>
<p>We will need the <em>design matrix</em>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{X} =
\begin{bmatrix}
1 &amp; x_1 \\
1 &amp; x_2 \\
\vdots &amp; \vdots \\
1 &amp; x_N
\end{bmatrix}.
\end{split}\]</div>
<p>The design matrix <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> is a <span class="math notranslate nohighlight">\(N\times 2\)</span> matrix with the first column being just one and the second column being the observed inputs.
We will also need, the <em>vector of observed outputs</em>:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y} = y_{1:N} = (y_1, \dots, y_N),
\]</div>
<p>and the <em>vector of weights</em>:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{w} = (w_0, w_1).
\]</div>
<p>I hope that you remember how to do <a class="reference external" href="https://en.wikipedia.org/wiki/Matrix_multiplication">matrix-vector multiplication</a>.
Notice what we get when we multiply the design matrix <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> with the weight vector <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\mathbf{X}\mathbf{w} &amp;=
\begin{bmatrix}
1 &amp; x_1 \\
1 &amp; x_2 \\
\vdots &amp; \vdots \\
1 &amp; x_N
\end{bmatrix}\cdot
\begin{bmatrix}
w_0\\
w_1
\end{bmatrix}\\
&amp;=
\begin{bmatrix}
w_0 + w_1 x_1 \\
w_0 + w_1 x_2 \\
\vdots\\
w_0 + w_1 x_N
\end{bmatrix}.
\end{split}
\end{split}\]</div>
<p>Wow! So, <span class="math notranslate nohighlight">\(\mathbf{X}\mathbf{w}\)</span> is an <span class="math notranslate nohighlight">\(N\)</span>-dimensional vector that contains the predictions of our linear model at the observed inputs.
If we subtract this vector from the vector of observed outputs <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>, we get the prediction errors:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{y} - \mathbf{X}\mathbf{w} =
\begin{bmatrix}
y_1 - w_0 - w_1 x_1\\
y_2 - w_0 - w_1 x_2\\
\vdots
y_N - w_0 - w_1 x_N
\end{bmatrix}.
\end{split}\]</div>
<p>Okay. Now recall that the [Euclidian norm](<a class="reference external" href="https://en.wikipedia.org/wiki/Norm_(mathematics)">https://en.wikipedia.org/wiki/Norm_(mathematics)</a> <span class="math notranslate nohighlight">\(\parallel\mathbf{v}\parallel\)</span> of a vector is the square root of the sum of the squares of its components.
Hmm.
Let’s take the square of the Euclidian norm of the error vector.
It is:</p>
<div class="math notranslate nohighlight">
\[
\parallel \mathbf{y} - \mathbf{X}\mathbf{w}\parallel^2 =
\sum_{i=1}^N(y_i - w_0 - w_1x_i)^2.
\]</div>
<p>But this is just sum of square errors, i.e., we have shown that:</p>
<div class="math notranslate nohighlight">
\[
L(w_0, w_1) = L(\mathbf{w}) = \parallel \mathbf{y} - \mathbf{X}\mathbf{w}\parallel^2.
\]</div>
<p>We have managed to express the loss function using linear algebra.
The mathematical problem of finding the best weight vector is now:</p>
<div class="math notranslate nohighlight">
\[
\min_{\mathbf{w}} L(\mathbf{w}) = \min_{\mathbf{w}} \parallel \mathbf{y} - \mathbf{X}\mathbf{w}\parallel^2.
\]</div>
<p>This form is much more convenient mathematically.
Remember that to solve the minimization problem, we need to take the gradient of <span class="math notranslate nohighlight">\(L(\mathbf{w})\)</span> with respect to <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> and set the result equal to zero.
This form, allows us to take derivatives in a much easier way.
But there is one more thing that we could do before we take the gradient.
Notice that the Euclidian norm of a vector <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> satisfies:</p>
<div class="math notranslate nohighlight">
\[
\parallel \mathbf{v}\parallel^2 = \mathbf{v}^T\mathbf{v},
\]</div>
<p>where we are thinking of <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> as a column matrix and <span class="math notranslate nohighlight">\(\mathbf{v}^T\)</span> is the transpose of <span class="math notranslate nohighlight">\(\mathbf{v}\)</span>, i.e., a row matrix.
To prove the equality, we start from the right hand side:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\mathbf{v}^T\mathbf{v} &amp;=
\begin{bmatrix}
v_1 &amp; v_2 &amp; \cdots &amp; v_N
\end{bmatrix}\cdot
\begin{bmatrix}
v_1\\
v_2\\
\vdots\\
v_N
\end{bmatrix}\\
&amp;= \sum_{i=1}^N v_i^2\\
&amp;= \parallel \mathbf{v}\parallel^2.
\end{split}
\end{split}\]</div>
<p>Interesting! So we can rewrite the sum of square errors as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
L(\mathbf{w}) &amp;= \parallel \mathbf{y} - \mathbf{X}\mathbf{w}\parallel^2
&amp;= \left(\mathbf{y} - \mathbf{X}\mathbf{w}\right)^T\left(\mathbf{y} - \mathbf{X}\mathbf{w}\right)\\
&amp;= \left[\mathbf{y}^T - \left(\mathbf{X}\mathbf{w}\right)^T\right]\left(\mathbf{y} - \mathbf{X}\mathbf{w}\right)\\
&amp;= \left(\mathbf{y}^T - \mathbf{w}^T\mathbf{X}^T\right)\left(\mathbf{y} - \mathbf{X}\mathbf{w}\right)\\
&amp;= \mathbf{y}^T\mathbf{y} - \mathbf{w}^T\mathbf{X}^T\mathbf{y}
- \mathbf{y}^T\mathbf{X}\mathbf{w} + \mathbf{w}^T\mathbf{X}^T\mathbf{X}\mathbf{w}
\end{split}
\end{split}\]</div>
<p>Now, because <span class="math notranslate nohighlight">\(\mathbf{w}^T\mathbf{X}^T\mathbf{y}\)</span> is just a number (think about the dimensions <span class="math notranslate nohighlight">\((1\times 2)\times (2\times N)\times (N \times 1) = 1\times 1\)</span>), it is the same as its transpose, i.e.,</p>
<div class="math notranslate nohighlight">
\[
\mathbf{w}^T\mathbf{X}^T\mathbf{y} = \left(\mathbf{w}^T\mathbf{X}^T\mathbf{y}\right)^T =
\mathbf{y}^T\mathbf{X}\mathbf{w}.
\]</div>
<p>Using this fact, we can write:</p>
<div class="math notranslate nohighlight">
\[
L(\mathbf{w}) = \mathbf{y}^T\mathbf{y} - 2\mathbf{w}^T\mathbf{X}^T\mathbf{y}
 + \mathbf{w}^T\mathbf{X}^T\mathbf{X}\mathbf{w}.
\]</div>
<p>Now we can take the gradient with respect to <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\nabla_{\mathbf{w}}L(\mathbf{w}) &amp;=
\nabla_{\mathbf{w}}\left[\mathbf{y}^T\mathbf{y} - 2\mathbf{w}^T\mathbf{X}^T\mathbf{y}
 + \mathbf{w}^T\mathbf{X}^T\mathbf{X}\mathbf{w}\right]\\
&amp;= -2\mathbf{X}^T\mathbf{y} + 2\mathbf{X}^T\mathbf{X}\mathbf{w}.
\end{split}
\end{split}\]</div>
<p>Okay, I do admit that I did some derivative magic there.
But the result is correct.
If you really want to understand it, you would have to work out the gradient of the following <span class="math notranslate nohighlight">\(\mathbf{w}^T\mathbf{u}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{w}^T\mathbf{A}\mathbf{w}\)</span> where <span class="math notranslate nohighlight">\(\mathbf{u}\)</span> is a 2-dimensional vector and <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> is a <span class="math notranslate nohighlight">\(2\times 2\)</span> matrix.</p>
<p>Setting the gradient to zero, yields the following linear system:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{X}^T\mathbf{X}\mathbf{w} = \mathbf{X}^T\mathbf{y}.
\]</div>
<p>The bottom line: to find the best <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> you must solve this linear system!
As I will show you in a while, for more complex models that remain linear in the parameters you basically have to do exactly the same thing but with a different design matrix.
By the way, if you work out the analytical solution for a linear model with 2 parameters you will get exactly the expression with the correlation between <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> we derived in the <a class="reference internal" href="../lecture14/linear-regression-with-one-variable.html#lecture14-linear-regression-with-one-variance"><span class="std std-ref">previous lecture</span></a>.</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./lecture15"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Lecture 15: Linear regression</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="example-linear-regression.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Example: Linear regression with a single variable</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Ilias Bilionis (ibilion[at]purdue.edu)<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>